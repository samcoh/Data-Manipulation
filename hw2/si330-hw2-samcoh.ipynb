{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 - Answering Real-World Questions Regular Expressions\n",
    "\n",
    "\n",
    "## Due: Friday, Sep 28, 2018,  11:59:00pm\n",
    "\n",
    "### Submission instructions\n",
    "After completing this homework, you will turn in two files via `Canvas` ->  `Assignments` -> `Homework 2`:\n",
    "Your Notebook, named `si330-hw2-YOUR_UNIQUE_NAME.ipynb` and\n",
    "the HTML file, named `si330-hw2-YOUR_UNIQUE_NAME.html`\n",
    "\n",
    "\n",
    "#### Name:  Samantha Cohen\n",
    "#### Uniqname: samcoh\n",
    "#### People you worked with: Rhea and Tori \n",
    "\n",
    "\n",
    "## Objectives\n",
    "After completing this homework assignment, you should\n",
    "* know how to use basic regular expressions\n",
    "* have gained more experience with composite data structures and sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "We will be using a larger version of the Enron email dataset that we used in this week's lab. \n",
    "For this assignment, you will be using a sample of 50,000 email messages from a large \n",
    "database of over 600,000 email \n",
    "messages generated by 158 employees of the Enron Corporation and acquired\n",
    "by the Federal Energy Regulatory Commission during its investigation after the company's collapse. \n",
    "The Enron scandal, publicized in October 2001, eventually led to the bankruptcy of the \n",
    "Enron Corporation - one of the largest corporate bankruptcy in U.S. history. \n",
    "Using this 50,000 email sample dataset, you will be answering the following three questions:\n",
    "\n",
    "## Questions\n",
    "1. Which two people exchanged the most email?\n",
    "1. What fraction of the emails were replies?\n",
    "1. What are the 20 most common words used in the \"Subject\" lines?\n",
    "\n",
    ">Note: you can re-use a lot of the code from this week's lab in this homework assignment, except that here we are asking for **complete email addresses**, and the lab just asked for the **username**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# the CSV we are loading has some fields with a large size,\n",
    "# so we need to up the field size limit to something big\n",
    "# (the value below is the maximum number a 32bit signed integer can hold)\n",
    "csv.field_size_limit(2**31 - 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "### Part 1.1 Load the data\n",
    "\n",
    "**We recommend you develop your code using the email_sample_5000.csv (from the lab) and then switch to the email_sample_50k.csv file for your final run.**\n",
    "\n",
    "`email_sample_50k.csv` is available in compressed form on Canvas; you'll have to uncompress it before using it in your final run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "email_data_file_name = \"email_sample_50k.csv\" # CHANGE ME LATER: remember to change this to email_sample_50k.csv for your final run\n",
    "\n",
    "email_data = []\n",
    "with open(email_data_file_name, 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader: \n",
    "        email_data.append(row)\n",
    "\n",
    "print(len(email_data))\n",
    "\n",
    "# CHANGE ME: Add code here to load the data\n",
    "# Hint: look at the code from the lab\n",
    "#email_data[0]['message'].split('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2 Spitting email headers from bodies\n",
    "Email messages consist of two parts: the headers and the body.  They are separated by two newline characters (```\\n\\n```).\n",
    "It's helpful to separate the two into a list of tuples: the list has a tuple for each email;  the first \n",
    "element of the tuple is the headers; the second is the body.  Why bother with this?  Because if we don't we might\n",
    "accidentally include headers that were included as part of a reply or forward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_bodies = [tuple(email['message'].split('\\n\\n')) for email in email_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message-ID: <30795301.1075855687494.JavaMail.evans@thyme>\n",
      "Date: Mon, 16 Oct 2000 06:44:00 -0700 (PDT)\n",
      "From: phillip.allen@enron.com\n",
      "To: zimam@enron.com\n",
      "Subject: FW: fixed forward or other Collar floor gas price terms\n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: Phillip K Allen\n",
      "X-To: zimam@enron.com\n",
      "X-cc: \n",
      "X-bcc: \n",
      "X-Folder: \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail\n",
      "X-Origin: Allen-P\n",
      "X-FileName: pallen.nsf\n"
     ]
    }
   ],
   "source": [
    "# Print the headers for the 10-th email\n",
    "print(headers_bodies[9][0])\n",
    "#print(headers_bodies[18][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. Buckner,\n"
     ]
    }
   ],
   "source": [
    "# Print the body for the 10-th email\n",
    "print(headers_bodies[9][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "### Q1: Which two people exchanged the most email?\n",
    "This is mostly a repeat of the final question from this week's lab.\n",
    "The main differences are:\n",
    "\n",
    "1. We're using a bigger data set.  \n",
    "2. We're asking for **complete email addresses**, not just the sender username.\n",
    "\n",
    "Choose your regular expression for extracting the sender and especially the recipient email addresses carefully: **each email message can be sent to multiple recipients.**\n",
    "Look at some email headers with multiple recipients to figure out what a `To:` field looks like when it contains more than one email address.\n",
    "\n",
    "Your output should consist of a single line that contains two email addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'defaultdict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c5517307de71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#(.*?)\\n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mconversation_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0memail\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheaders_bodies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_match\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memail\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDOTALL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'defaultdict' is not defined"
     ]
    }
   ],
   "source": [
    "to_match = r'From:\\s*(.*?)\\nTo:\\s*(.*?)\\n'\n",
    "#with the ? its saying after the first line break you see stop (gives you back the first match it sees); greedy without question mark -- will give you back as much as possible \n",
    "#in bracket dot and star dont have regular expression meaning \n",
    "\n",
    "#to_match = r'From:\\s*([\\w\\.\\-@]*)\\nTo:\\s*([\\w\\.\\-\\'@,\\s]*)\\nSubject:'\n",
    "#to_match = r'From:\\s*([\\w\\.\\-@]*)\\nTo:\\s*([\\w\\.\\-\\'@,\\s]*)\\n'\n",
    "#(.*?)\\n\n",
    "\n",
    "conversation_count = defaultdict(int)\n",
    "for email in headers_bodies:\n",
    "    match = re.findall(to_match, email[0], re.DOTALL)\n",
    "    #print(match)\n",
    "    #break\n",
    "    #print(email[0])\n",
    "    #break\n",
    "    if match: \n",
    "        for x in match[0][1].split(', '): \n",
    "            if x: #will get rid of empty lists \n",
    "                sorted_tuples = sorted((match[0][0],x.strip()))  \n",
    "                conversation_count[tuple(sorted_tuples)] += 1\n",
    "#print(conversation_count)\n",
    "#for x in list(conversation_count.keys())[:10]: \n",
    "    #print(x, conversation_count[x])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('eric.bass@enron.com', 'shanna.husser@enron.com'), 728)\n"
     ]
    }
   ],
   "source": [
    "sorted_conversation_count = sorted(conversation_count.items(), key = lambda x: x[1], reverse= True)\n",
    "print(sorted_conversation_count[0])\n",
    "#count = 0 \n",
    "# for x in sorted_conversation_count[:10]:\n",
    "#     if count == 0: \n",
    "#         print(\"These are the top 2 people who exchanged the most emails: \")\n",
    "#         print(\"\\t{} and {} exchanged emails {} times\".format(sorted_conversation_count[0][0][0],sorted_conversation_count[0][0][1],sorted_conversation_count[0][1]))\n",
    "#     if count == 0: \n",
    "#         print(\"\")\n",
    "#         print(\"These the top 10 people who exchanged the most emails: \")\n",
    "#         count +=1 \n",
    "#     print(\"\\t{}. {} and {} exchanged emails {} times\".format(count,x[0][0],x[0][1], x[1]))\n",
    "#     count+=1 \n",
    "#print(\"The top two people who exchanged the most emails are: {} and {}\".format(sorted_conversation_count[0][0][0],sorted_conversation_count[0][0][1]))\n",
    "#print(\"{} and {} exchanged {} emails\".format(sorted_conversation_count[0][0][0],sorted_conversation_count[0][0][1],sorted_conversation_count[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BONUS (Above and Beyond)\n",
    "Which headers, other than the \"To:\" header, can contain recipients? Note that each of those headers (including To:) can also contain multiple recipients. For the bonus, write\n",
    "another code block that accounts for these additional headers in answering Q1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: What fraction of the email messages were replies?\n",
    "In email messages, replies are typically indicated with a `Subject:` header that starts\n",
    "with \"Re:\".  So to answer this question you'll need to find the number of email messages\n",
    "whose `Subject:` header starts with \"Re: \" and then represent that number as a fraction of\n",
    "the total number of email messages (i.e. divide the number of replies by the total number of messages).\n",
    "\n",
    "##### Your output should show the fraction as a percentage with no decimal values and should look like:\n",
    "```65% of the email messages were replies.``` (Note: 65% is not necessarily the correct value; this is just an example)\n",
    "\n",
    "__Hint__: This is similar to extracting the sender email address, except all we want to do is\n",
    "determine whether the Subject header starts with \"Re: \".  We don't care about the rest of the header.\n",
    "\n",
    "__Hint__: Try using the .format() function to make your life easier when you're generating your output.\n",
    "\n",
    "#### BONUS (Above and Beyond)\n",
    "Can you do this in 4 lines of code or less? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27% of the email messages were replies.\n"
     ]
    }
   ],
   "source": [
    "to_match = r'Subject:\\s*(Re:)'\n",
    "total =[re.findall(to_match, email[0],re.IGNORECASE) for email in headers_bodies if re.findall(to_match, email[0], re.IGNORECASE)!= []]\n",
    "replies =round((len(total)/len(headers_bodies))*100)\n",
    "print(\"{}% of the email messages were replies.\".format(replies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Q3: What are the 20 most common words used in the \"Subject\" lines?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bit more complex than the previous question.  In this case, we're actually interested in the\n",
    "contents of the \"Subject:\" header.  In addition, we want to exclude strings that indicate the message is\n",
    "a reply (\"Re:\") or a forward (\"Fwd:\").  Finally, we want to exclude strings that represent commonly used\n",
    "\"stopwords\": words like \"a\", \"an\", \"and\", etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it a bit easier for you, we've generated a set of stopwords (we'll learn more about this next week):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopWords = {'then', 'was', 'over', 'such', 'him', 'shan', 'at', 'haven', 'as', 'off', 'all', 'of', 'are', 'in', 'm', 'out', 'into', 'too', 'didn', 'wasn', \"weren't\", 'through', \"mightn't\", 'below', 'on', 'will', 'there', 'needn', 'wouldn', 'why', 'have', 'yourself', \"needn't\", 'having', 'am', \"it's\", 'by', 'itself', 'they', 'he', 'being', 'hadn', 'mustn', 'don', \"she's\", 'where', 'yours', 'its', 'nor', 'not', 'that', 'the', 'who', 'our', 'these', 'up', 'their', 'himself', 'a', 'about', \"don't\", 'has', 're', 'to', 'more', 'doesn', 'both', 'which', 'any', 'ain', 'ourselves', 'had', 'this', 'while', 'herself', 'against', 'very', 'weren', 'myself', 'been', \"should've\", 'what', 'can', 'or', 'your', \"isn't\", \"wasn't\", 'does', 'how', \"you'll\", 'she', \"hasn't\", \"shouldn't\", 'my', 'once', 's', \"hadn't\", 'those', 'is', 'do', 'ours', 'but', \"wouldn't\", 'his', 'now', 'down', 'each', 'i', 'here', 'from', 'me', 'other', 'be', 'hers', \"you're\", 'until', 'further', 'y', 'own', 'again', 'just', \"haven't\", \"shan't\", 'under', 'when', \"doesn't\", 'and', \"won't\", 'no', 'above', 'them', 've', 'so', 'if', 'we', 'were', 'same', 'with', 'mightn', 'ma', 'for', 'hasn', 'couldn', 'after', 'aren', 'yourselves', \"you'd\", 'should', \"aren't\", 'o', \"didn't\", 'themselves', 'most', 'whom', 'shouldn', 'you', 'between', \"couldn't\", \"you've\", 'an', 'because', 'before', \"mustn't\", 'won', 'only', 'doing', 'some', 'her', 'did', 't', 'during', 'it', 'll', 'isn', \"that'll\", 'd', 'theirs', 'few', 'than', '-', '&'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general approach that you should use is to iterate through the headers_bodies list and extracting the\n",
    "contents of the Subject: header (excluding Re: and Fwd:).  Then, assuming you have the contents in a string,\n",
    "split the string (using the ```.split()``` function). You should convert each of the resulting words to lowercase\n",
    "and count the occurences of each one that isn't a stopword.  We've done this kind of thing before using ```defaultdict(int)```.\n",
    "\n",
    "Here's some code to get you started.  It assumes you're in the middle of looping though the headers and bodies\n",
    "list.  \n",
    "```python\n",
    "subject = re.search(...) # we're not going to tell you how to do this :)\n",
    "lower_subject = subject.lower()\n",
    "words = lower_subject.split()\n",
    "for word in words:\n",
    "    if word not in stopWords:\n",
    "        # do something with this word\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_match = r'Subject: +(?!(Re:)|(Fw:)|(Fwd:))(.+)\\n'\n",
    "#parenthesis that start with a question mark means i dont want to take this as a group \n",
    "#! mark is about the rest of it \n",
    "common = defaultdict(int)\n",
    "for email in headers_bodies:\n",
    "    match = re.findall(to_match, email[0],re.IGNORECASE)\n",
    "    if match: \n",
    "        subject = match[0][3]\n",
    "        lower_subject = subject.lower()\n",
    "        words = lower_subject.split()\n",
    "        for word in words:\n",
    "            if word not in stopWords:\n",
    "                common[word]+= 1\n",
    "#print(common)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the 20 most commonly used words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. meeting (meeting was used 1285 times)\n",
      "2. 2001 (2001 was used 1003 times)\n",
      "3. enron (enron was used 964 times)\n",
      "4. new (new was used 836 times)\n",
      "5. report (report was used 794 times)\n",
      "6. request (request was used 771 times)\n",
      "7. update (update was used 725 times)\n",
      "8. weekly (weekly was used 549 times)\n",
      "9. 2000 (2000 was used 511 times)\n",
      "10. power (power was used 478 times)\n",
      "11. access (access was used 469 times)\n",
      "12. conference (conference was used 458 times)\n",
      "13. gas (gas was used 445 times)\n",
      "14. market (market was used 406 times)\n",
      "15. price (price was used 399 times)\n",
      "16. global (global was used 387 times)\n",
      "17. management (management was used 386 times)\n",
      "18. energy (energy was used 365 times)\n",
      "19. risk (risk was used 365 times)\n",
      "20. office (office was used 356 times)\n"
     ]
    }
   ],
   "source": [
    "sorted_common = sorted(common.items(), key = lambda x: x[1], reverse = True)\n",
    "count = 0\n",
    "for word,value in sorted_common[:20]: \n",
    "    count +=1 \n",
    "    print(\"{}. {} ({} was used {} times)\".format(count,word,word,value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS: Full dataset\n",
    "We have also made available the complete data set (https://drive.google.com/file/d/1bHAezkzeWqAJ9cDjrCgleO2ANGXI1YWT/view?usp=sharing), which is approximately 1.4GB when uncompressed.  If you're\n",
    "up it, you can try running your code against this dataset (but you probably don't want to do your development work with it --- only try the full dataset after you get the small one working!).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
